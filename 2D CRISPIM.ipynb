{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__\n",
        "#!pip uninstall tensorflow\n",
        "#!pip install tensorflow\n",
        "#%tensorflow_version 1.x\n",
        "\n",
        "import keras\n",
        "print(keras.__version__)\n",
        "!pip install keras==2.14.0\n"
      ],
      "metadata": {
        "id": "jwgfMXZuKHOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZl234a0Sxyl"
      },
      "outputs": [],
      "source": [
        "# 2D TRAIN AND VAL Data generator\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def load_image(file_path):\n",
        "    image = Image.open(file_path)\n",
        "\n",
        "    # Crop in square form\n",
        "    image = image.crop((0, 0, 256, 256))\n",
        "\n",
        "    # Convert image to NumPy array\n",
        "    image_array = np.array(image)\n",
        "\n",
        "    return image_array\n",
        "\n",
        "def train_val_data_generator(blur_folder, crisp_folder, batch_size):\n",
        "\n",
        "    validation_split = 0.05\n",
        "    num_validation = int(validation_split * batch_size) + 1\n",
        "    num_train = batch_size - num_validation\n",
        "\n",
        "    # Infinite loop to yield batches during training\n",
        "    while True: # Random selection of images in multiple folders\n",
        "\n",
        "        # Initialize lists to store mini-stacks and corresponding crisp images\n",
        "        X_batch = []\n",
        "        Y_batch = []\n",
        "        count = 0;\n",
        "        print(f\"Generating 2D pairs...\")\n",
        "        # Iterate over the indices in the batch\n",
        "        while count != batch_size:\n",
        "            count+=1\n",
        "\n",
        "            folders = [\"480490_541480\", \"500480_533880\", \"500484_508050\", \"533470_523780\"]\n",
        "\n",
        "            # Define the mapping of folders to num_images\n",
        "            folder_to_num_images = {\n",
        "                \"480490_541480\": 2408,\n",
        "                \"500480_533880\": 2888,\n",
        "                \"500484_508050\": 2888,\n",
        "                \"533470_523780\": 2862\n",
        "            }\n",
        "            random_folder = random.choice(folders)\n",
        "\n",
        "            num_images = folder_to_num_images.get(random_folder, 0)\n",
        "\n",
        "            random_ind = random.randint(200, num_images-200)\n",
        "\n",
        "            crisp_image = load_image(os.path.join(crisp_folder, f\"{random_folder}\", f\"{random_folder}_{random_ind:04d}.tif\"))\n",
        "            blur_image = load_image(os.path.join(blur_folder, f\"{random_folder}\", f\"{random_ind:05d}.tif\"))\n",
        "            X_batch.append(blur_image)\n",
        "            Y_batch.append(crisp_image)\n",
        "\n",
        "            #print(f\": {count}/{batch_size}, {random_folder}_{random_ind:04d}.tif\")\n",
        "\n",
        "        X_train, Y_train = X_batch[:num_train], Y_batch[:num_train]\n",
        "        X_val, Y_val = X_batch[num_train:], Y_batch[num_train:]\n",
        "\n",
        "\n",
        "        print(f\"Shape of X_train: {X_train[0].shape}\")\n",
        "        print(f\"Shape of Y_train: {Y_train[0].shape}\")\n",
        "\n",
        "        print(f\"Image pairs prepared. Train/Val = {len(X_train)}/{len(X_val)}\")\n",
        "\n",
        "        yield (X_train, Y_train), (X_val, Y_val)\n",
        "\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "train_blur_folder = \"gdrive/My Drive/Noisy_data/\"\n",
        "train_crisp_folder = \"gdrive/My Drive/Crisp_data/\"\n",
        "\n",
        "\n",
        "batch_size = 5\n",
        "\n",
        "train_val_data = train_val_data_generator(train_blur_folder, train_crisp_folder, batch_size)\n",
        "\n",
        "(X_train, Y_train), (X_val, Y_val) = next(train_val_data)\n",
        "\n",
        "X_min_value = np.min(X_train[0])\n",
        "X_max_value = np.max(X_train[0])\n",
        "Y_min_value = np.min(Y_train[0])\n",
        "Y_max_value = np.max(Y_train[0])\n",
        "\n",
        "print(f\"X_train min/max Value: {X_min_value}/{X_max_value}\")\n",
        "print(f\"Y_train min/max Value: {Y_min_value}/{Y_max_value}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "av8JvHxYwDaW"
      },
      "outputs": [],
      "source": [
        "# UNet USING TRAIN VAL GENERATOR\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.models import save_model\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import pearsonr\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from tensorflow.keras.metrics import MeanAbsoluteError\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import pathlib\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import MaxPool2D\n",
        "from tensorflow.keras.layers import UpSampling2D\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Activation\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "\n",
        "import io\n",
        "import random\n",
        "\n",
        "# Parameters\n",
        "conv_filt       = 32\n",
        "kernel_size     = 3\n",
        "activation      = \"relu\"\n",
        "padding         = \"same\"\n",
        "pool_size       = (2, 2)\n",
        "\n",
        "# TRAIN\n",
        "optimizer       = \"Adam\"\n",
        "learning_rate   = 1e-4\n",
        "validation_split = 0.1\n",
        "train_eval_ratio = 0.9\n",
        "input_shape = [256,256,1]\n",
        "\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "################################################################################\n",
        "\n",
        "# Simple 2D U-Net\n",
        "def get_model_unet(input_shape = input_shape,\n",
        "                             conv_filt=32,\n",
        "                             kernel_size=3,\n",
        "                             activation=\"relu\",\n",
        "                             padding=\"same\",\n",
        "                             pool_size=pool_size):\n",
        "    conv_args = {\"activation\": activation,\n",
        "                 \"padding\": padding,\n",
        "                 \"kernel_size\": kernel_size}\n",
        "    input_ = Input(shape=input_shape)\n",
        "    conv1 = Conv2D(filters=conv_filt, **conv_args)(input_)\n",
        "    conv2 = Conv2D(filters=conv_filt, **conv_args)(conv1)\n",
        "    pool1 = MaxPool2D(pool_size=pool_size)(conv2)\n",
        "    #\n",
        "    conv3 = Conv2D(filters=2*conv_filt, **conv_args)(pool1)\n",
        "    conv4 = Conv2D(filters=2*conv_filt, **conv_args)(conv3)\n",
        "    pool2 = MaxPool2D(pool_size=pool_size)(conv4)\n",
        "    #\n",
        "    conv5 = Conv2D(filters=4*conv_filt, **conv_args)(pool2)\n",
        "    conv6 = Conv2D(filters=2*conv_filt, **conv_args)(conv5)\n",
        "    up1 = UpSampling2D(size=(2,2))(conv6)\n",
        "    #\n",
        "    conc1 = Concatenate()([conv4, up1])\n",
        "    #\n",
        "    conv7 = Conv2D(filters=2*conv_filt, **conv_args)(conc1)\n",
        "    conv8 = Conv2D(filters=conv_filt, **conv_args)(conv7)\n",
        "    up2 = UpSampling2D(size=(2,2))(conv8)\n",
        "    #\n",
        "    conc2 = Concatenate()([conv2, up2])\n",
        "    #\n",
        "    conv9 = Conv2D(filters=conv_filt, **conv_args)(conc2)\n",
        "    conv10 = Conv2D(filters=conv_filt, **conv_args)(conv9)\n",
        "    #\n",
        "    output = Conv2D(filters=1, kernel_size=1, activation=None)(conv10)\n",
        "    #\n",
        "    model = keras.Model(inputs=[input_], outputs=[output])\n",
        "    return model\n",
        "\n",
        "# Define model\n",
        "model   = get_model_unet(\n",
        "    input_shape=input_shape,\n",
        "    conv_filt=conv_filt,\n",
        "    kernel_size=kernel_size,\n",
        "    activation=activation,\n",
        "    padding=padding,\n",
        "    pool_size=pool_size)\n",
        "\n",
        "loss_fn = keras.losses.MeanSquaredError()\n",
        "optimizer = keras.optimizers.Adam(learning_rate=1e-4)\n",
        "model.compile(optimizer=optimizer,\n",
        "          loss=loss_fn,\n",
        "          metrics=[\"mse\"])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "################################################################################\n",
        "\n",
        "\n",
        "# Train the model using the data generator\n",
        "train_val_data = train_val_data_generator(train_blur_folder, train_crisp_folder, batch_size)\n",
        "\n",
        "psnr_history = []\n",
        "ssim_history = []\n",
        "pcc_history = []\n",
        "\n",
        "# Training loop\n",
        "epochs = 1000  # Adjust as needed\n",
        "for epoch in range(epochs):\n",
        "    (X_train, Y_train), (X_val, Y_val) = next(train_val_data)\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(np.array(X_train), np.array(Y_train), epochs=1, validation_data=(np.array(X_val), np.array(Y_val)))\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    val_preds = model.predict(np.array(X_val))\n",
        "\n",
        "    val_preds_min_value = np.min(val_preds[0])\n",
        "    val_preds_max_value = np.max(val_preds[0])\n",
        "    gt_min_value = np.min(Y_val[0])\n",
        "    gt_max_value = np.max(Y_val[0])\n",
        "\n",
        "    print(f\"val_preds Min/Max Value: {val_preds_min_value} / {val_preds_max_value}\")\n",
        "    print(f\"ground-truth Min/Max Value: {gt_min_value} / {gt_max_value}\")\n",
        "\n",
        "    # Calculate and print PSNR and SSIM for the test set\n",
        "    psnr_val_list = [psnr(np.squeeze(Y_val[i]), np.squeeze(val_preds[i]), data_range=65535.0) for i in range(len(Y_val))]\n",
        "    ssim_val_list = [ssim(np.squeeze(Y_val[i]), np.squeeze(val_preds[i]), data_range=65535.0) for i in range(len(Y_val))]\n",
        "    pcc_val_list = [pearsonr(np.squeeze(Y_val[i]).ravel(), np.squeeze(val_preds[i]).ravel())[0] for i in range(len(Y_val))]\n",
        "\n",
        "    # Report the average PSNR, SSIM, and PCC for the test set\n",
        "    average_psnr_val = np.mean(psnr_val_list)\n",
        "    average_ssim_val = np.mean(ssim_val_list)\n",
        "    average_pcc_val = np.mean(pcc_val_list)\n",
        "\n",
        "    # Store PSNR, SSIM, and PCC values in history lists\n",
        "    psnr_history.append(average_psnr_val)\n",
        "    ssim_history.append(average_ssim_val)\n",
        "    pcc_history.append(average_pcc_val)\n",
        "\n",
        "    # Plotting real-time PSNR and SSIM\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    # Plot PSNR\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.plot(psnr_history, label='PSNR')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('PSNR')\n",
        "    plt.title('Real-time PSNR during Validation')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot SSIM\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.plot(ssim_history, label='SSIM', color='orange')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('SSIM')\n",
        "    plt.title('Real-time SSIM during Validation')\n",
        "    plt.legend()\n",
        "\n",
        "     # Plot PCC\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.plot(pcc_history, label='PCC', color='green')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('PCC')\n",
        "    plt.title('Real-time PCC during Validation')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{epochs} - PSNR: {average_psnr_val}, SSIM: {average_ssim_val}')\n",
        "\n",
        "    # Display the original (noisy) image\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(np.squeeze(X_val[0]) * 1.0, cmap='gray', vmin=0, vmax=500)\n",
        "    plt.title('Original (Noisy) Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Display the predicted (crisp) image\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(np.squeeze(val_preds[0]) * 1.0, cmap='gray', vmin=0, vmax=500)\n",
        "    plt.title('Predicted (Crisp) Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Display the ground truth image\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(np.squeeze(Y_val[0]) * 1.0, cmap='gray', vmin=0, vmax=500)\n",
        "    plt.title('Ground Truth Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "# Get the current date and time\n",
        "current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "# Define the model file name with the current time\n",
        "model_file_name = f'model_ds_{current_time}.keras'\n",
        "model_save_path = f'gdrive/My Drive/{model_file_name}'\n",
        "\n",
        "# Save the model to Google Drive\n",
        "save_model(model, model_save_path)\n",
        "print(f'Model saved to {model_save_path}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2D TEST Data generator (RANDOM NOISE)\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def load_image(file_path):\n",
        "    image = Image.open(file_path)\n",
        "\n",
        "    # Crop in square form\n",
        "    image = image.crop((244, 144, 500, 400))\n",
        "\n",
        "    # Convert image to NumPy array\n",
        "    image_array = np.array(image) / 1 #65535.0\n",
        "\n",
        "    return image_array\n",
        "\n",
        "def test_data_generator(blur_folder, crisp_folder, batch_size):\n",
        "\n",
        "    validation_split = 0.1\n",
        "    num_validation = int(validation_split * batch_size) + 1\n",
        "    num_train = batch_size - num_validation\n",
        "\n",
        "    # Infinite loop to yield batches during training\n",
        "    while True: # Random selection of images in multiple folders\n",
        "\n",
        "        # Initialize lists to store mini-stacks and corresponding crisp images\n",
        "        X_test = []\n",
        "        Y_test = []\n",
        "        count = 0;\n",
        "        print(f\"Generating TEST 2D pairs...\")\n",
        "        # Iterate over the indices in the batch\n",
        "        while count != batch_size:\n",
        "            count+=1\n",
        "\n",
        "            random_ind = random.randint(1000, 2000)\n",
        "\n",
        "            print(f\": {count}/{batch_size}, {random_ind:05d}.tif\")\n",
        "\n",
        "            crisp_image = load_image(os.path.join(crisp_folder, f\"500480_482220_{random_ind:04d}.tif\"))\n",
        "\n",
        "\n",
        "            std_dev = random.randint(30, 40)\n",
        "\n",
        "            # Generate Gaussian noise with the same shape as the image\n",
        "            noise = np.random.normal(loc=0, scale=std_dev, size=crisp_image.shape)\n",
        "\n",
        "            # Add the noise to the image\n",
        "            noisy_image = crisp_image + noise\n",
        "\n",
        "            # Clip the pixel values to the valid range [0, 65535.0]\n",
        "            noisy_image = np.clip(noisy_image, 0, 65535.0)\n",
        "\n",
        "            # Assuming 16-bit images, changing the scale to [0,1]\n",
        "            X_test.append(noisy_image)\n",
        "            Y_test.append(crisp_image)\n",
        "\n",
        "\n",
        "        print(f\"Shape of X_train: {X_test[0].shape}\")\n",
        "        print(f\"Shape of Y_train: {Y_test[0].shape}\")\n",
        "        print(f\"TEST image pairs prepared. Testlength = {len(X_test)}\")\n",
        "\n",
        "        yield X_test, Y_test\n",
        "\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "test_blur_folder = \"gdrive/My Drive/Noisy_data/500480_482220/\"\n",
        "test_crisp_folder = \"gdrive/My Drive/Crisp_data/500480_482220/\"\n",
        "\n",
        "\n",
        "batch_size = 5\n",
        "\n",
        "test_data = test_data_generator(test_blur_folder, test_crisp_folder, batch_size)\n",
        "\n",
        "X_test, Y_test = next(test_data)\n",
        "\n",
        "X_min_value = np.min(X_test[0])\n",
        "X_max_value = np.max(X_test[0])\n",
        "Y_min_value = np.min(Y_test[0])\n",
        "Y_max_value = np.max(Y_test[0])\n",
        "\n",
        "print(f\"X_test min/max Value: {X_min_value}/{X_max_value}\")\n",
        "print(f\"Y_test min/max Value: {Y_min_value}/{Y_max_value}\")"
      ],
      "metadata": {
        "id": "mqy9kBsrw4DZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpoJHqrGIkCR"
      },
      "outputs": [],
      "source": [
        "# Display the image of test result\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.models import save_model\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from scipy.stats import pearsonr\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.restoration import denoise_tv_bregman\n",
        "\n",
        "\n",
        "# Load the saved model from Google Drive\n",
        "model_save_path = f'gdrive/My Drive/model_ds_20231203_182307.keras'\n",
        "loaded_model = load_model(model_save_path)\n",
        "\n",
        "batch_size = 20\n",
        "\n",
        "test_data = test_data_generator(test_blur_folder, test_crisp_folder, batch_size)\n",
        "X_test, Y_test = next(test_data)\n",
        "\n",
        "# Use the loaded model to predict the crisp image\n",
        "test_pred = loaded_model.predict(np.array(X_test))\n",
        "\n",
        "#################################################################################\n",
        "\n",
        "# Define functions for metrics calculation\n",
        "def calculate_metrics(original, denoised):\n",
        "    psnr_value = psnr(np.squeeze(original), np.squeeze(denoised), data_range=65535.0)\n",
        "    ssim_value = ssim(np.squeeze(original), np.squeeze(denoised), data_range=65535.0)\n",
        "    pcc_value, _ = pearsonr(original.flatten(), denoised.flatten())\n",
        "    return psnr_value, ssim_value, pcc_value\n",
        "\n",
        "# Function to display images and calculate metrics\n",
        "def display_and_calculate_metrics(batch_index, original, denoised_tv, denoised_cv2, predicted, ground_truth):\n",
        "    # Display images\n",
        "    plt.figure(figsize=(30, 10))\n",
        "\n",
        "    plt.subplot(1, 5, 1)\n",
        "    plt.imshow(original, cmap='gray', vmin=0, vmax=500)\n",
        "    plt.title('Original')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 5, 2)\n",
        "    plt.imshow(denoised_tv, cmap='gray', vmin=0, vmax=500)\n",
        "    plt.title('Denoised (TV)')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 5, 3)\n",
        "    plt.imshow(denoised_cv2, cmap='gray', vmin=0, vmax=500)\n",
        "    plt.title('Denoised (cv2)')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 5, 4)\n",
        "    plt.imshow(predicted, cmap='gray', vmin=0, vmax=500)\n",
        "    plt.title('Predicted')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 5, 5)\n",
        "    plt.imshow(ground_truth, cmap='gray', vmin=0, vmax=500)\n",
        "    plt.title('Ground Truth')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Calculate and print metrics\n",
        "    psnr_tv, ssim_tv, pcc_tv = calculate_metrics(ground_truth, denoised_tv)\n",
        "    psnr_cv2, ssim_cv2, pcc_cv2 = calculate_metrics(ground_truth, denoised_cv2)\n",
        "    psnr_pred, ssim_pred, pcc_pred = calculate_metrics(ground_truth, predicted)\n",
        "\n",
        "\n",
        "    '''\n",
        "    print(f\"Batch {batch_index + 1} Metrics:\")\n",
        "    print(f\"PSNR (TV): {psnr_tv:.4f}, SSIM (TV): {ssim_tv:.4f}, PCC (TV): {pcc_tv:.4f}\")\n",
        "    print(f\"PSNR (cv2): {psnr_cv2:.4f}, SSIM (cv2): {ssim_cv2:.4f}, PCC (cv2): {pcc_cv2:.4f}\")\n",
        "    print(f\"PSNR (Prediction): {psnr_pred:.4f}, SSIM (Prediction): {ssim_pred:.4f}, PCC (Prediction): {pcc_pred:.4f}\")\n",
        "    print()\n",
        "    '''\n",
        "\n",
        "# Lists to store metric values for each image\n",
        "psnr_tv_list, ssim_tv_list, pcc_tv_list = [], [], []\n",
        "psnr_cv2_list, ssim_cv2_list, pcc_cv2_list = [], [], []\n",
        "psnr_pred_list, ssim_pred_list, pcc_pred_list = [], [], []\n",
        "\n",
        "\n",
        "# Iterate through batches\n",
        "num_batches = len(X_test)\n",
        "average_psnr_tv, average_ssim_tv, average_pcc_tv = 0, 0, 0\n",
        "average_psnr_cv2, average_ssim_cv2, average_pcc_cv2 = 0, 0, 0\n",
        "average_psnr_pred, average_ssim_pred, average_pcc_pred = 0, 0, 0\n",
        "\n",
        "for batch_index in range(num_batches):\n",
        "    original_image = X_test[batch_index]\n",
        "    ground_truth_image = Y_test[batch_index]\n",
        "    predicted_image = test_pred[batch_index]\n",
        "\n",
        "\n",
        "\n",
        "    # Denoise using denoise_tv_bregman\n",
        "    denoised_tv = denoise_tv_bregman(original_image, weight=0.1)\n",
        "\n",
        "    # Convert the images to 8-bit unsigned\n",
        "    bit8_original_image = cv2.convertScaleAbs(original_image)\n",
        "\n",
        "    # Denoise using cv2.fastNlMeansDenoising\n",
        "    denoised_cv2 = cv2.fastNlMeansDenoising(bit8_original_image, None, h=10, templateWindowSize=7, searchWindowSize=21)\n",
        "\n",
        "    # Display images and calculate metrics\n",
        "    display_and_calculate_metrics(batch_index, original_image, denoised_tv, denoised_cv2, predicted_image, ground_truth_image)\n",
        "\n",
        "    # Update running totals for average metrics\n",
        "    psnr_tv, ssim_tv, pcc_tv = calculate_metrics(ground_truth_image, denoised_tv)\n",
        "    psnr_cv2, ssim_cv2, pcc_cv2 = calculate_metrics(ground_truth_image, denoised_cv2)\n",
        "    psnr_pred, ssim_pred, pcc_pred = calculate_metrics(ground_truth_image, predicted_image)\n",
        "\n",
        "    # Append metrics to lists\n",
        "    psnr_tv_list.append(psnr_tv)\n",
        "    ssim_tv_list.append(ssim_tv)\n",
        "    pcc_tv_list.append(pcc_tv)\n",
        "\n",
        "    psnr_cv2_list.append(psnr_cv2)\n",
        "    ssim_cv2_list.append(ssim_cv2)\n",
        "    pcc_cv2_list.append(pcc_cv2)\n",
        "\n",
        "    psnr_pred_list.append(psnr_pred)\n",
        "    ssim_pred_list.append(ssim_pred)\n",
        "    pcc_pred_list.append(pcc_pred)\n",
        "\n",
        "    average_psnr_tv += psnr_tv\n",
        "    average_ssim_tv += ssim_tv\n",
        "    average_pcc_tv += pcc_tv\n",
        "\n",
        "    average_psnr_cv2 += psnr_cv2\n",
        "    average_ssim_cv2 += ssim_cv2\n",
        "    average_pcc_cv2 += pcc_cv2\n",
        "\n",
        "    average_psnr_pred += psnr_pred\n",
        "    average_ssim_pred += ssim_pred\n",
        "    average_pcc_pred += pcc_pred\n",
        "\n",
        "# Calculate average metrics across all batches\n",
        "average_psnr_tv /= num_batches\n",
        "average_ssim_tv /= num_batches\n",
        "average_pcc_tv /= num_batches\n",
        "\n",
        "average_psnr_cv2 /= num_batches\n",
        "average_ssim_cv2 /= num_batches\n",
        "average_pcc_cv2 /= num_batches\n",
        "\n",
        "average_psnr_pred /= num_batches\n",
        "average_ssim_pred /= num_batches\n",
        "average_pcc_pred /= num_batches\n",
        "\n",
        "# Print average metrics\n",
        "print(\"Average Metrics Across All Batches:\")\n",
        "print(f\"PSNR (TV): {average_psnr_tv:.4f}, SSIM (TV): {average_ssim_tv:.4f}, PCC (TV): {average_pcc_tv:.4f}\")\n",
        "print(f\"PSNR (cv2): {average_psnr_cv2:.4f}, SSIM (cv2): {average_ssim_cv2:.4f}, PCC (cv2): {average_pcc_cv2:.4f}\")\n",
        "print(f\"PSNR (Prediction): {average_psnr_pred:.4f}, SSIM (Prediction): {average_ssim_pred:.4f}, PCC (Prediction): {average_pcc_pred:.4f}\")\n",
        "\n",
        "# Plot graphs\n",
        "image_numbers = np.arange(1, num_batches + 1)\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# PSNR\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(image_numbers, psnr_tv_list, marker='o', label='TV')\n",
        "plt.plot(image_numbers, psnr_cv2_list, marker='o', label='cv2')\n",
        "plt.plot(image_numbers, psnr_pred_list, marker='o', label='Prediction')\n",
        "plt.xlabel('Image Number')\n",
        "plt.ylabel('PSNR')\n",
        "plt.legend()\n",
        "plt.title('PSNR Comparison')\n",
        "\n",
        "# SSIM\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(image_numbers, ssim_tv_list, marker='o', label='TV')\n",
        "plt.plot(image_numbers, ssim_cv2_list, marker='o', label='cv2')\n",
        "plt.plot(image_numbers, ssim_pred_list, marker='o', label='Prediction')\n",
        "plt.xlabel('Image Number')\n",
        "plt.ylabel('SSIM')\n",
        "plt.legend()\n",
        "plt.title('SSIM Comparison')\n",
        "\n",
        "# PCC\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(image_numbers, pcc_tv_list, marker='o', label='TV')\n",
        "plt.plot(image_numbers, pcc_cv2_list, marker='o', label='cv2')\n",
        "plt.plot(image_numbers, pcc_pred_list, marker='o', label='Prediction')\n",
        "plt.xlabel('Image Number')\n",
        "plt.ylabel('PCC')\n",
        "plt.legend()\n",
        "plt.title('PCC Comparison')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}