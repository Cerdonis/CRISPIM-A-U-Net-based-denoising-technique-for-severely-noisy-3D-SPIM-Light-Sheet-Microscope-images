{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNUBu78X8UMh"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__\n",
        "#!pip uninstall tensorflow\n",
        "#!pip install tensorflow\n",
        "#%tensorflow_version 1.x\n",
        "\n",
        "import keras\n",
        "print(keras.__version__)\n",
        "!pip install keras==2.14.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZl234a0Sxyl"
      },
      "outputs": [],
      "source": [
        "# 3D TRAIN AND VAL Data generator\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def load_image(file_path):\n",
        "    image = Image.open(file_path)\n",
        "\n",
        "    # Crop in square form\n",
        "    image = image.crop((0, 0, 256, 256))\n",
        "\n",
        "    # Convert image to NumPy array\n",
        "    image_array = np.array(image)\n",
        "\n",
        "    return image_array\n",
        "\n",
        "def train_val_data_generator(blur_folder, crisp_folder, mini_stack_height, batch_size):\n",
        "\n",
        "    validation_split = 0.05\n",
        "    num_validation = int(validation_split * batch_size) + 1\n",
        "    num_train = batch_size - num_validation\n",
        "\n",
        "    # Infinite loop to yield batches during training\n",
        "    while True: # Random selection of images in multiple folders\n",
        "\n",
        "        # Initialize lists to store mini-stacks and corresponding crisp images\n",
        "        X_batch = []\n",
        "        Y_batch = []\n",
        "        count = 0;\n",
        "        print(f\"Generating 2D pairs...\")\n",
        "        # Iterate over the indices in the batch\n",
        "        while count != batch_size:\n",
        "            count+=1\n",
        "\n",
        "            folders = [\"480490_541480\", \"500480_533880\", \"500484_508050\", \"533470_523780\"]\n",
        "\n",
        "            # Define the mapping of folders to num_images\n",
        "            folder_to_num_images = {\n",
        "                \"480490_541480\": 2408,\n",
        "                \"500480_533880\": 2888,\n",
        "                \"500484_508050\": 2888,\n",
        "                \"533470_523780\": 2862\n",
        "            }\n",
        "            random_folder = random.choice(folders)\n",
        "\n",
        "            num_images = folder_to_num_images.get(random_folder, 0)\n",
        "\n",
        "            random_ind = random.randint(200, num_images-200)\n",
        "\n",
        "            crisp_image = load_image(os.path.join(crisp_folder, f\"{random_folder}\", f\"{random_folder}_{random_ind:04d}.tif\"))\n",
        "            blur_mini_stack = [\n",
        "                            load_image(os.path.join(blur_folder, f\"{random_folder}\", f\"{random_ind - mini_stack_height // 2 + j:05d}.tif\"))\n",
        "                            for j in range((mini_stack_height))\n",
        "                        ]\n",
        "\n",
        "\n",
        "            X_batch.append(np.stack(blur_mini_stack, axis=0))\n",
        "            Y_batch.append(crisp_image)\n",
        "\n",
        "            #print(f\": {count}/{batch_size}, {random_folder}_{random_ind:04d}.tif\")\n",
        "\n",
        "        X_train, Y_train = X_batch[:num_train], Y_batch[:num_train]\n",
        "        X_val, Y_val = X_batch[num_train:], Y_batch[num_train:]\n",
        "\n",
        "\n",
        "        print(f\"Shape of X_train: {X_train[0].shape}\")\n",
        "        print(f\"Shape of Y_train: {Y_train[0].shape}\")\n",
        "\n",
        "        print(f\"Image pairs prepared. Train/Val = {len(X_train)}/{len(X_val)}\")\n",
        "\n",
        "        yield (X_train, Y_train), (X_val, Y_val)\n",
        "\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "train_blur_folder = \"gdrive/My Drive/Noisy_data/\"\n",
        "train_crisp_folder = \"gdrive/My Drive/Crisp_data/\"\n",
        "\n",
        "\n",
        "batch_size = 3\n",
        "\n",
        "mini_stack_height = 4\n",
        "\n",
        "train_val_data = train_val_data_generator(train_blur_folder, train_crisp_folder, mini_stack_height, batch_size)\n",
        "\n",
        "(X_train, Y_train), (X_val, Y_val) = next(train_val_data)\n",
        "\n",
        "X_min_value = np.min(X_train[0])\n",
        "X_max_value = np.max(X_train[0])\n",
        "Y_min_value = np.min(Y_train[0])\n",
        "Y_max_value = np.max(Y_train[0])\n",
        "\n",
        "print(f\"X_train min/max Value: {X_min_value}/{X_max_value}\")\n",
        "print(f\"Y_train min/max Value: {Y_min_value}/{Y_max_value}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "av8JvHxYwDaW"
      },
      "outputs": [],
      "source": [
        "# 3D UNet USING TRAIN VAL GENERATOR\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.models import save_model\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import pearsonr\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from tensorflow.keras.metrics import MeanAbsoluteError\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import pathlib\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import MaxPool2D\n",
        "from tensorflow.keras.layers import UpSampling2D\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Activation\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "\n",
        "import io\n",
        "import random\n",
        "\n",
        "batch_size = 3\n",
        "mini_stack_height = 16\n",
        "\n",
        "\n",
        "################################################################################\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from tensorflow.keras.layers import Reshape\n",
        "\n",
        "\n",
        "def unet_3d():\n",
        "\n",
        "    inputs = layers.Input(shape=(16, 256, 256, 1))\n",
        "    conv1 = layers.Conv3D(filters=32, activation=\"relu\", padding=\"same\", kernel_size=3)(inputs)\n",
        "    conv2 = layers.Conv3D(filters=32, activation=\"relu\", padding=\"same\", kernel_size=3)(conv1)\n",
        "    pool1 = layers.MaxPooling3D(pool_size=(2, 2, 2))(conv2)\n",
        "\n",
        "    conv3 = layers.Conv3D(filters=64, activation=\"relu\", padding=\"same\", kernel_size=3)(pool1)\n",
        "    conv4 = layers.Conv3D(filters=64, activation=\"relu\", padding=\"same\", kernel_size=3)(conv3)\n",
        "    pool2 = layers.MaxPooling3D(pool_size=(2, 2, 2))(conv4)\n",
        "\n",
        "    conv5 = layers.Conv3D(filters=128, activation=\"relu\", padding=\"same\", kernel_size=3)(pool2)\n",
        "    conv6 = layers.Conv3D(filters=128, activation=\"relu\", padding=\"same\", kernel_size=3)(conv5)\n",
        "    pool3 = layers.MaxPooling3D(pool_size=(2, 2, 2))(conv6)\n",
        "\n",
        "    conv7 = layers.Conv3D(filters=256, activation=\"relu\", padding=\"same\", kernel_size=3)(pool3)\n",
        "    conv8 = layers.Conv3D(filters=256, activation=\"relu\", padding=\"same\", kernel_size=3)(conv7)\n",
        "\n",
        "    up1 = layers.UpSampling3D(size=(2, 2, 2))(conv8)\n",
        "    conc1 = layers.Concatenate()([conv6, up1])\n",
        "\n",
        "    conv9 = layers.Conv3D(filters=128, activation=\"relu\", padding=\"same\", kernel_size=3)(conc1)\n",
        "    conv10 = layers.Conv3D(filters=128, activation=\"relu\", padding=\"same\", kernel_size=3)(conv9)\n",
        "\n",
        "    up2 = layers.UpSampling3D(size=(2, 2, 2))(conv10)\n",
        "    conc2 = layers.Concatenate()([conv4, up2])\n",
        "\n",
        "    conv11 = layers.Conv3D(filters=64, activation=\"relu\", padding=\"same\", kernel_size=3)(conc2)\n",
        "    conv12 = layers.Conv3D(filters=64, activation=\"relu\", padding=\"same\", kernel_size=3)(conv11)\n",
        "\n",
        "    up3 = layers.UpSampling3D(size=(2, 2, 2))(conv12)\n",
        "    conc3 = layers.Concatenate()([conv2, up3])\n",
        "\n",
        "    conv13 = layers.Conv3D(filters=32, activation=\"relu\", padding=\"same\", kernel_size=3)(conc3)\n",
        "    conv14 = layers.Conv3D(filters=32, activation=\"relu\", padding=\"same\", kernel_size=3)(conv13)\n",
        "\n",
        "    # Add an additional pooling layer to reduce the height dimension to 1\n",
        "    pool4 = layers.MaxPooling3D(pool_size=(16, 1, 1))(conv14)\n",
        "\n",
        "    # Change the last Conv3D layer to Conv2D\n",
        "    output = layers.Conv2D(filters=1, kernel_size=1, activation=None)(pool4)\n",
        "\n",
        "    # Reshape the output to be 2D\n",
        "    output = layers.Reshape((256, 256, 1))(output)\n",
        "\n",
        "    model = keras.Model(inputs=[inputs], outputs=[output])\n",
        "    return model\n",
        "\n",
        "\n",
        "model = unet_3d()\n",
        "\n",
        "loss_fn = keras.losses.MeanSquaredError()\n",
        "optimizer = keras.optimizers.Adam(learning_rate=1e-4)\n",
        "#model.compile(optimizer=optimizer, loss=loss_fn, metrics=[\"mse\"])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.summary()\n",
        "\n",
        "################################################################################\n",
        "\n",
        "\n",
        "# Train the model using the data generator\n",
        "train_val_data = train_val_data_generator(train_blur_folder, train_crisp_folder, mini_stack_height, batch_size)\n",
        "\n",
        "psnr_history = []\n",
        "ssim_history = []\n",
        "pcc_history = []\n",
        "\n",
        "# Training loop\n",
        "epochs = 2000  # Adjust as needed\n",
        "for epoch in range(epochs):\n",
        "    (X_train, Y_train), (X_val, Y_val) = next(train_val_data)\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{epochs}')\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(np.array(X_train), np.array(Y_train), epochs=1, validation_data=(np.array(X_val), np.array(Y_val)))\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    val_preds = model.predict(np.array(X_val))\n",
        "\n",
        "    val_preds_min_value = np.min(val_preds[0])\n",
        "    val_preds_max_value = np.max(val_preds[0])\n",
        "    gt_min_value = np.min(Y_val[0])\n",
        "    gt_max_value = np.max(Y_val[0])\n",
        "\n",
        "    print(f\"val_preds Min/Max Value: {val_preds_min_value} / {val_preds_max_value}\")\n",
        "    print(f\"ground-truth Min/Max Value: {gt_min_value} / {gt_max_value}\")\n",
        "\n",
        "    # Calculate and print PSNR and SSIM for the test set\n",
        "    psnr_val_list = [psnr(np.squeeze(Y_val[i]), np.squeeze(val_preds[i]), data_range=65535.0) for i in range(len(Y_val))]\n",
        "    ssim_val_list = [ssim(np.squeeze(Y_val[i]), np.squeeze(val_preds[i]), data_range=65535.0) for i in range(len(Y_val))]\n",
        "    pcc_val_list = [pearsonr(np.squeeze(Y_val[i]).ravel(), np.squeeze(val_preds[i]).ravel())[0] for i in range(len(Y_val))]\n",
        "\n",
        "    # Report the average PSNR, SSIM, and PCC for the test set\n",
        "    average_psnr_val = np.mean(psnr_val_list)\n",
        "    average_ssim_val = np.mean(ssim_val_list)\n",
        "    average_pcc_val = np.mean(pcc_val_list)\n",
        "\n",
        "    # Store PSNR, SSIM, and PCC values in history lists\n",
        "    psnr_history.append(average_psnr_val)\n",
        "    ssim_history.append(average_ssim_val)\n",
        "    pcc_history.append(average_pcc_val)\n",
        "\n",
        "    # Plotting real-time PSNR and SSIM\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    # Plot PSNR\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.plot(psnr_history, label='PSNR')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('PSNR')\n",
        "    plt.title('Real-time PSNR during Validation')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot SSIM\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.plot(ssim_history, label='SSIM', color='orange')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('SSIM')\n",
        "    plt.title('Real-time SSIM during Validation')\n",
        "    plt.legend()\n",
        "\n",
        "     # Plot PCC\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.plot(pcc_history, label='PCC', color='green')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('PCC')\n",
        "    plt.title('Real-time PCC during Validation')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{epochs} - PSNR: {average_psnr_val}, SSIM: {average_ssim_val}')\n",
        "\n",
        "    # Display the original (noisy) image\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(np.squeeze(X_val[0][mini_stack_height//2]) * 1.0, cmap='gray', vmin=0, vmax=500)\n",
        "    plt.title('Original (Noisy) Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Display the predicted (crisp) image\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(np.squeeze(val_preds[0]) * 1.0, cmap='gray', vmin=0, vmax=500)\n",
        "    plt.title('Predicted (Crisp) Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Display the ground truth image\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(np.squeeze(Y_val[0]) * 1.0, cmap='gray', vmin=0, vmax=500)\n",
        "    plt.title('Ground Truth Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "# Get the current date and time\n",
        "current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "# Define the model file name with the current time\n",
        "model_file_name = f'model_ds_{current_time}.keras'\n",
        "model_save_path = f'gdrive/My Drive/{model_file_name}'\n",
        "\n",
        "# Save the model to Google Drive\n",
        "save_model(model, model_save_path)\n",
        "print(f'Model saved to {model_save_path}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzRn-Rt-tR42"
      },
      "outputs": [],
      "source": [
        "# 3D TEST Data generator (RANDOM NOISE)\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def load_image(file_path):\n",
        "    image = Image.open(file_path)\n",
        "\n",
        "    # Crop in square form\n",
        "    image = image.crop((244, 144, 500, 400))\n",
        "\n",
        "    # Convert image to NumPy array\n",
        "    image_array = np.array(image)\n",
        "\n",
        "    return image_array\n",
        "\n",
        "def test_data_generator(blur_folder, crisp_folder, mini_stack_height, batch_size):\n",
        "\n",
        "    # Infinite loop to yield batches during training\n",
        "    while True: # Random selection of images in multiple folders\n",
        "\n",
        "        # Initialize lists to store mini-stacks and corresponding crisp images\n",
        "        X_test = []\n",
        "        Y_test = []\n",
        "        count = 0;\n",
        "        print(f\"Generating TEST 3D stacks...\")\n",
        "        # Iterate over the indices in the batch\n",
        "        while count != batch_size:\n",
        "            count+=1\n",
        "\n",
        "            random_ind = random.randint(800, 2000)\n",
        "\n",
        "            print(f\": {count}/{batch_size}, {random_ind:05d}.tif\")\n",
        "\n",
        "            crisp_image = load_image(os.path.join(crisp_folder, f\"500480_482220_{random_ind:04d}.tif\"))\n",
        "\n",
        "\n",
        "            noisy_mini_stack = [\n",
        "                np.clip(\n",
        "                    load_image(os.path.join(crisp_folder, f\"500480_482220_{random_ind - mini_stack_height // 2 + j:04d}.tif\"))\n",
        "                    + np.random.normal(loc=0, scale=random.randint(30, 40), size=crisp_image.shape),\n",
        "                    0,\n",
        "                    65535.0\n",
        "                )\n",
        "                for j in range(mini_stack_height)\n",
        "            ]\n",
        "\n",
        "            # Assuming 16-bit images, changing the scale to [0,1]\n",
        "            X_test.append(np.stack(noisy_mini_stack, axis=0))\n",
        "            Y_test.append(crisp_image)\n",
        "\n",
        "\n",
        "        print(f\"Shape of X_train: {X_test[0].shape}\")\n",
        "        print(f\"Shape of Y_train: {Y_test[0].shape}\")\n",
        "        print(f\"TEST pairs prepared. Test length = {len(X_test)}\")\n",
        "\n",
        "        yield X_test, Y_test\n",
        "\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "test_blur_folder = \"gdrive/My Drive/Noisy_data/500480_482220/\"\n",
        "test_crisp_folder = \"gdrive/My Drive/Crisp_data/500480_482220/\"\n",
        "\n",
        "\n",
        "batch_size = 3\n",
        "mini_stack_height = 4\n",
        "\n",
        "test_data = test_data_generator(test_blur_folder, test_crisp_folder, mini_stack_height, batch_size)\n",
        "\n",
        "X_test, Y_test = next(test_data)\n",
        "\n",
        "X_min_value = np.min(X_test[0])\n",
        "X_max_value = np.max(X_test[0])\n",
        "Y_min_value = np.min(Y_test[0])\n",
        "Y_max_value = np.max(Y_test[0])\n",
        "\n",
        "print(f\"X_test min/max Value: {X_min_value}/{X_max_value}\")\n",
        "print(f\"Y_test min/max Value: {Y_min_value}/{Y_max_value}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rpoJHqrGIkCR"
      },
      "outputs": [],
      "source": [
        "# TEST, compare 2D and 3D CRISPIM\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.models import save_model\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from scipy.stats import pearsonr\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.restoration import denoise_tv_bregman\n",
        "\n",
        "\n",
        "# Load the saved model from Google Drive\n",
        "model_2d_path = f'gdrive/My Drive/model_ds_20231203_182307.keras'\n",
        "model_3d_path = f'gdrive/My Drive/model_ds_20231213_180605.keras'\n",
        "crispim_2d = load_model(model_2d_path)\n",
        "crispim_3d = load_model(model_3d_path)\n",
        "\n",
        "batch_size = 20\n",
        "mini_stack_height = 16\n",
        "\n",
        "test_data = test_data_generator(test_blur_folder, test_crisp_folder, mini_stack_height, batch_size)\n",
        "X_test, Y_test = next(test_data)\n",
        "X_test_single_im = [stack[mini_stack_height//2] for stack in X_test]\n",
        "\n",
        "# Use the loaded model to predict the crisp image\n",
        "test_pred_2d = crispim_2d.predict(np.array(X_test_single_im))\n",
        "test_pred_3d = crispim_3d.predict(np.array(X_test))\n",
        "\n",
        "#################################################################################\n",
        "\n",
        "# Define functions for metrics calculation\n",
        "def calculate_metrics(original, denoised):\n",
        "    psnr_value = psnr(np.squeeze(original), np.squeeze(denoised), data_range=65535.0)\n",
        "    ssim_value = ssim(np.squeeze(original), np.squeeze(denoised), data_range=65535.0)\n",
        "    pcc_value, _ = pearsonr(original.flatten(), denoised.flatten())\n",
        "    return psnr_value, ssim_value, pcc_value\n",
        "\n",
        "# Function to display images and calculate metrics\n",
        "def display_and_calculate_metrics(original, predicted_2d, predicted_3d, ground_truth):\n",
        "    # Display images\n",
        "    plt.figure(figsize=(30, 10))\n",
        "\n",
        "    plt.subplot(1, 4, 1)\n",
        "    plt.imshow(original, cmap='gray', vmin=0, vmax=500)\n",
        "    plt.title('Original')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 4, 2)\n",
        "    plt.imshow(predicted_2d, cmap='gray', vmin=0, vmax=500)\n",
        "    plt.title('2D CRISPIM')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 4, 3)\n",
        "    plt.imshow(predicted_3d, cmap='gray', vmin=0, vmax=500)\n",
        "    plt.title('3D CRISPIM')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 4, 4)\n",
        "    plt.imshow(ground_truth, cmap='gray', vmin=0, vmax=500)\n",
        "    plt.title('Ground Truth')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Calculate and print metrics\n",
        "    psnr_2d, ssim_2d, pcc_2d = calculate_metrics(ground_truth, predicted_2d)\n",
        "    psnr_3d, ssim_3d, pcc_3d = calculate_metrics(ground_truth, predicted_3d)\n",
        "\n",
        "\n",
        "# Lists to store metric values for each image\n",
        "psnr_2d_list, ssim_2d_list, pcc_2d_list = [], [], []\n",
        "psnr_3d_list, ssim_3d_list, pcc_3d_list = [], [], []\n",
        "\n",
        "# Iterate through batches\n",
        "num_batches = len(X_test)\n",
        "\n",
        "# Calculate metrics for each batch\n",
        "for batch_index in range(num_batches):\n",
        "    original_image = X_test_single_im[batch_index]\n",
        "    ground_truth_image = Y_test[batch_index]\n",
        "    predicted_image_2d = test_pred_2d[batch_index]\n",
        "    predicted_image_3d = test_pred_3d[batch_index]\n",
        "\n",
        "    # Display images and calculate metrics\n",
        "    display_and_calculate_metrics(original_image, predicted_image_2d, predicted_image_3d, ground_truth_image)\n",
        "\n",
        "    # Update running totals for average metrics\n",
        "    psnr_2d, ssim_2d, pcc_2d = calculate_metrics(ground_truth_image, predicted_image_2d)\n",
        "    psnr_3d, ssim_3d, pcc_3d = calculate_metrics(ground_truth_image, predicted_image_3d)\n",
        "\n",
        "    # Append metrics to lists\n",
        "    psnr_2d_list.append(psnr_2d)\n",
        "    ssim_2d_list.append(ssim_2d)\n",
        "    pcc_2d_list.append(pcc_2d)\n",
        "\n",
        "    psnr_3d_list.append(psnr_3d)\n",
        "    ssim_3d_list.append(ssim_3d)\n",
        "    pcc_3d_list.append(pcc_3d)\n",
        "\n",
        "# Calculate average metrics across all batches\n",
        "average_psnr_2d = np.mean(psnr_2d_list)\n",
        "average_ssim_2d = np.mean(ssim_2d_list)\n",
        "average_pcc_2d = np.mean(pcc_2d_list)\n",
        "\n",
        "average_psnr_3d = np.mean(psnr_3d_list)\n",
        "average_ssim_3d = np.mean(ssim_3d_list)\n",
        "average_pcc_3d = np.mean(pcc_3d_list)\n",
        "\n",
        "# Print average metrics\n",
        "print(\"Average Metrics Across All Batches:\")\n",
        "print(f\"PSNR (2D CRISPIM): {average_psnr_2d:.4f}, SSIM (2D CRISPIM): {average_ssim_2d:.4f}, PCC (2D CRISPIM): {average_pcc_2d:.4f}\")\n",
        "print(f\"PSNR (3D CRISPIM): {average_psnr_3d:.4f}, SSIM (3D CRISPIM): {average_ssim_3d:.4f}, PCC (3D CRISPIM): {average_pcc_3d:.4f}\")\n",
        "\n",
        "# Plot graphs\n",
        "image_numbers = np.arange(1, num_batches + 1)\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# PSNR\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(image_numbers, psnr_2d_list, marker='o', label='2D CRISPIM')\n",
        "plt.plot(image_numbers, psnr_3d_list, marker='o', label='3D CRISPIM')\n",
        "plt.xlabel('Image Number')\n",
        "plt.ylabel('PSNR')\n",
        "plt.legend()\n",
        "plt.title('PSNR Comparison')\n",
        "\n",
        "# SSIM\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(image_numbers, ssim_2d_list, marker='o', label='2D CRISPIM')\n",
        "plt.plot(image_numbers, ssim_3d_list, marker='o', label='3D CRISPIM')\n",
        "plt.xlabel('Image Number')\n",
        "plt.ylabel('SSIM')\n",
        "plt.legend()\n",
        "plt.title('SSIM Comparison')\n",
        "\n",
        "# PCC\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(image_numbers, pcc_2d_list, marker='o', label='2D CRISPIM')\n",
        "plt.plot(image_numbers, pcc_3d_list, marker='o', label='3D CRISPIM')\n",
        "plt.xlabel('Image Number')\n",
        "plt.ylabel('PCC')\n",
        "plt.legend()\n",
        "plt.title('PCC Comparison')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}